{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbdcf2ef-ba39-44c8-97e0-80e1ddc6804b",
   "metadata": {
    "id": "dbdcf2ef-ba39-44c8-97e0-80e1ddc6804b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "from itertools import permutations\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adY8qZ9fsVl7",
   "metadata": {
    "id": "adY8qZ9fsVl7"
   },
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a854574c-14fe-4325-be47-770f17c74b82",
   "metadata": {
    "id": "a854574c-14fe-4325-be47-770f17c74b82"
   },
   "outputs": [],
   "source": [
    "def load_ALL_TRADE_data():\n",
    "  ### This is a function that loads accordingly the dataset from MACycle organization, which holds an Improved version of the UN Comtrade bulk.\n",
    "  ### Returns a dataframe with clean data.\n",
    "  data = pd.read_csv('trade_data_full.csv')\n",
    "  data = data.drop(data[data['period'] == 201].index)     #deletion of false data\n",
    "  data = data.drop(data[data['period'] == 20].index)\n",
    "  data = data.drop(data[data['partnercode'].isna()].index)     #deletion of na data (missing data)\n",
    "  data = data.drop(data[data['new_tradevalue'].isna()].index)\n",
    "  data = data[['period', 'reportercode', 'tradeflowcode', 'partnercode', 'new_tradevalue']]     #only conserving important columns.\n",
    "  data['period'] = data['period'].astype('int16')     #casting from string to int identifiers.\n",
    "  data['reportercode'] = data['reportercode'].astype('int16')\n",
    "  data['tradeflowcode'] = data['tradeflowcode'].astype('int16')\n",
    "  data['partnercode'] = data['partnercode'].astype('int16')\n",
    "  data = data.replace({'reportercode':{490:158,251:250,699:356,381:380,579:578,757:756,842:840}})    #replacing country codes with new formal codes.\n",
    "  data = data.replace({'partnercode':{490:158,251:250,699:356,381:380,579:578,757:756,842:840}})     #el 490 se reeplaza por el 158, el 251 por el 250...\n",
    "  return data\n",
    "\n",
    "def get_ISO_df():\n",
    "    ### This is a function that obtains all official ISO codes for the final selected countries, numerical (ISO-3) and the original strings.\n",
    "    ### Return a dataframe with ISO codes information.\n",
    "    ISO_codes = pd.read_csv('FINAL ALL countries ISO.csv', encoding='latin1')     #obtain final country's list\n",
    "    ISO_codes = ISO_codes[1:177] #todos los items de la lista\n",
    "    info = pd.read_csv('ISO_codes.csv')     #obtain ISO codes for each country\n",
    "    info.columns = info.columns.str.replace('English short name lower case', 'Name')\n",
    "    drop_c = ['Alpha-2 code', 'Name', 'ISO 3166-2']\n",
    "    info.drop(drop_c, inplace=True, axis=1)\n",
    "    dict_letters = {}\n",
    "    for i in range(len(info)):\n",
    "        dict_letters[info['Numeric code'].iloc[i]] = info['Alpha-3 code'].iloc[i]\n",
    "    new_letters = []\n",
    "    vals = list(ISO_codes['List of Countries ISO'].values)\n",
    "    for i in range(len(ISO_codes)):\n",
    "        if vals[i] == '531': new_letters.append('CUW')     #solve few discrepancies with countries ISO codes.\n",
    "        elif vals[i] == '534': new_letters.append('SXM')\n",
    "        else: new_letters.append(dict_letters.get(int(vals[i]), 0))\n",
    "    ISO_codes['ISO-3'] = new_letters\n",
    "    return ISO_codes\n",
    "\n",
    "def convert_name_links(links):\n",
    "    ### This is a function that converts the countries' name accordingly to the new formal form.\n",
    "    ### Takes a dictionary of links.\n",
    "    ### Returns THE SAME links with different country names.\n",
    "    change = [['United States', 'United States Of America', 840],\n",
    "         ['Korea, Rep. of', 'Korea, Republic of (South Korea)', 410],\n",
    "         ['Russian Federation', 'Russia', 643],\n",
    "         ['Taiwan Province of China', 'Taiwan', 158],\n",
    "         ['Poland, Rep. of', 'Poland', 616],\n",
    "         ['British Virgin Islands', 'Virgin Islands, British', 92],\n",
    "         ['Curaçao, Kingdom of the Netherlands', 'Curaçao', 531],\n",
    "         ['Czech Rep.', 'Czech Republic', 203],\n",
    "         ['Kazakhstan, Rep. of', 'Kazakhstan', 398],\n",
    "         ['Bahrain, Kingdom of', 'Bahrain', 48],\n",
    "         ['Curaçao and Sint Maarten', 'Sint Maarten', 534],\n",
    "         ['Venezuela, Rep. Bolivariana de', 'Venezuela', 862],\n",
    "         ['Slovak Rep.', 'Slovakia', 703],\n",
    "         ['Slovenia, Rep. of', 'Slovenia', 705],\n",
    "         ['Bahamas, The', 'Bahamas', 44],\n",
    "         ['Egypt, Arab Rep. of', 'Egypt', 818],\n",
    "         ['Marshall Islands, Rep. of the', 'Marshall Islands', 584],\n",
    "         ['Estonia, Rep. of', 'Estonia', 233],\n",
    "         ['Croatia, Rep. of', 'Croatia', 191],\n",
    "         ['Serbia, Rep. of', 'Serbia', 688],\n",
    "         ['Dominican Rep.', 'Dominican Republic', 214],\n",
    "         ['Aruba, Kingdom of the Netherlands', 'Aruba', 533],\n",
    "         ['United States Virgin Islands', 'Virgin Islands, U.S.', 850],\n",
    "         ['Kosovo, Rep. of', 'Kosovo', 999],\n",
    "         ['Sint Maarten, Kingdom of the Netherlands', 'Sint Maarten', 534],\n",
    "         ['Azerbaijan, Rep. of', 'Azerbaijan', 31],\n",
    "         ['Belarus, Rep. of', 'Belarus', 112],\n",
    "         ['Iran, Islamic Rep. of', 'Iran', 364],\n",
    "         ['Congo, Dem. Rep. of the', 'Congo, the Democratic Republic of the', 180],\n",
    "         ['Turks and Caicos Islands', 'Turks and Caicos', 796],\n",
    "         ['North Macedonia, Republic of',\n",
    "          'Macedonia, the former Yugoslav Republic of',\n",
    "          807],\n",
    "         [\"Lao People's Dem. Rep.\", \"Lao People's Democratic Republic\", 418],\n",
    "         ['Tanzania, United Rep. of', 'Tanzania, United Republic of', 834],\n",
    "         ['Armenia, Rep. of', 'Armenia', 51],\n",
    "         ['Mozambique, Rep. of', 'Mozambique', 508],\n",
    "         ['Andorra, Principality of', 'Andorra', 20],\n",
    "         ['Ethiopia, The Federal Dem. Rep. of', 'Ethiopia', 231],\n",
    "         ['Congo, Rep. of', 'Congo', 178],\n",
    "         ['Mauritania, Islamic Rep. of', 'Mauritania', 478],\n",
    "         ['Kyrgyz Rep.', 'Kyrgyzstan', 417],\n",
    "         ['Syrian Arab Rep.', 'Syrian Arab Republic', 760],\n",
    "         ['St. Kitts and Nevis', 'Saint Kitts and Nevis', 659],\n",
    "         ['St. Vincent and the Grenadines', 'Saint Vincent and the Grenadines', 670],\n",
    "         ['Bonaire, St. Eustatius and Saba', 'Bonaire, Sint Eustatius and Saba', 535],\n",
    "         ['San Marino, Rep. of', 'San Marino', 674],\n",
    "         ['Cabo Verde', 'Cape Verde', 132],\n",
    "         ['Libya', 'Libyan Arab Jamahiriya', 434],\n",
    "         ['Fiji, Rep. of', 'Fiji', 242],\n",
    "         ['Eswatini, Kingdom of', 'Eswatini', 748],\n",
    "         ['St. Lucia', 'Saint Lucia', 662],\n",
    "         ['Palau, Rep. of', 'Palau', 585],\n",
    "         ['Yemen, Rep. of', 'Yemen', 887],\n",
    "         ['Madagascar, Rep. of', 'Madagascar', 450],\n",
    "         ['Moldova, Rep. of', 'Moldova, Republic of', 498],\n",
    "         ['Lesotho, Kingdom of', 'Lesotho', 426],\n",
    "         ['Uzbekistan, Rep. of', 'Uzbekistan', 860],\n",
    "         ['Tajikistan, Rep. of', 'Tajikistan', 762],\n",
    "         ['Eritrea, The State of', 'Eritrea', 232],\n",
    "         ['Guiana, French', 'French Guiana', 254],\n",
    "         ['Afghanistan, Islamic Rep. of', 'Afghanistan', 4],\n",
    "         ['Nauru, Rep. of', 'Nauru', 520],\n",
    "         ['Central African Rep.', 'Central African Republic', 140],\n",
    "         ['Equatorial Guinea, Rep. of', 'Equatorial Guinea', 226],\n",
    "         ['Gambia, The', 'Gambia', 270],\n",
    "         ['Saint Helena', 'Saint Helena, Ascension and Tristan da Cunha', 654],\n",
    "         ['Micronesia, Federated States of', 'Micronesia, Federated States of', 583],\n",
    "         ['Comoros, Union of the', 'Comoros', 174],\n",
    "         ['Wallis and Futuna Islands', 'Wallis and Futuna', 876],\n",
    "         ['Pitcairn Islands', 'Pitcairn', 612],\n",
    "         ['Holy See', 'Holy See (Vatican City State)', 336],\n",
    "                 ['China, P.R.: Hong Kong', 'Hong Kong', 344],\n",
    "                 ['China, P.R.: Macao', 'Macao', 446],\n",
    "                 ['China, P.R.: Mainland', 'China', 156],\n",
    "                 ['Netherlands, The', 'Netherlands', 528],\n",
    "             ['Türkiye, Rep of', 'Turkey', 792]]\n",
    "    change_values = [k[0] for k in change]\n",
    "    new_links = {}\n",
    "    for i in list(links.keys()): #el .keys indica la categoria de cada 'columna'\n",
    "        (nfrom, nto) = i\n",
    "        if nfrom in change_values:\n",
    "            nfrom = change[change_values.index(nfrom)][1]\n",
    "        if nto in change_values:\n",
    "            nto = change[change_values.index(nto)][1]\n",
    "        new_links[(nfrom,nto)] = links[i]\n",
    "    return new_links\n",
    "\n",
    "def removekey(d, key):\n",
    "    r = dict(d)\n",
    "    del r[key] #delete\n",
    "    return r\n",
    "\n",
    "def get_ISO_codes_from_df(ISO_codes):\n",
    "    dict_codes = {}\n",
    "    for i in ISO_codes.values:\n",
    "        dict_codes[i[0]] = i[1]\n",
    "    return dict_codes\n",
    "\n",
    "def ISO_dict_converter(links, ISO_codes):\n",
    "    ISO_converter = get_ISO_codes_from_df(ISO_codes)\n",
    "    final_data = {(ISO_converter[str(k[0])], ISO_converter[str(k[1])]): v for k, v in links.items()}\n",
    "    return final_data\n",
    "\n",
    "def get_reversedISO3_codes_from_df(ISO_codes):\n",
    "    dict_codes = {}\n",
    "    for i in list(ISO_codes.index):\n",
    "        dict_codes[i] = ISO_codes.loc[i][1]\n",
    "    return dict_codes\n",
    "\n",
    "def ISO_dict_converter3(links, ISO_codes):\n",
    "    ISO_converter = get_reversedISO3_codes_from_df(ISO_codes)\n",
    "    final_data = {(ISO_converter[(k[0])], ISO_converter[(k[1])]): v for k, v in links.items()}\n",
    "    return final_data\n",
    "\n",
    "def get_trade_in_higher_Rank(a, b, rankA, rankB): #rank indica cuan 'fiel' es un pais\n",
    "    return a if rankA < rankB else b \n",
    "\n",
    "def perc_diff(a,b):\n",
    "  ### This is a function that returns the percentage difference for 2 values.\n",
    "  a = abs(a)\n",
    "  b = abs(b)\n",
    "  if a == 0 and b == 0:\n",
    "    return 400\n",
    "  elif a == 0 or b == 0:\n",
    "    return 200\n",
    "  elif a == b:\n",
    "    return 0\n",
    "  else:\n",
    "    l = [a,b]\n",
    "    l.sort(reverse=True)\n",
    "    return (((l[0] - l[1]) / ((l[0] + l[1]) / 2)) * 100)\n",
    "\n",
    "def get_bilateral_trade(data, year, ISO_codes):\n",
    "  ### This is a function that obtains the trade flow for a desired year.\n",
    "  ### Takes as input all trade data, a desired year, and the ISO codes information.\n",
    "  ### Returns the desired year trade flow performing data curation as mentioned on the documentation.\n",
    "  data = data[data['period'] == year]\n",
    "  countries = list(get_ISO_codes_from_df(ISO_codes).keys())\n",
    "  all_links = list(permutations(countries, 2))\n",
    "  imports = {}\n",
    "  exports = {}\n",
    "  for i in range(len(data)):\n",
    "      nfromi = data['reportercode'].iloc[i]\n",
    "      ntoi = data['partnercode'].iloc[i]\n",
    "      nfrom = nfromi\n",
    "      nto = ntoi\n",
    "      link = (nfrom, nto)\n",
    "      flowcode = data['tradeflowcode'].iloc[i]\n",
    "      value = data['new_tradevalue'].iloc[i]\n",
    "      if (flowcode == 2) or (flowcode == 3):\n",
    "        exports[link] = value + exports.get(link, 0)\n",
    "      if (flowcode == 1) or (flowcode == 4):\n",
    "        imports[link] = value + imports.get(link, 0)\n",
    "  for key in imports:\n",
    "    imports[key] = int(imports[key]/1000000)\n",
    "  for key in exports:\n",
    "    exports[key] = int(exports[key]/1000000)\n",
    "  countries_diff = {}\n",
    "  green_countries = {}\n",
    "  for i in all_links:\n",
    "    (cfromi, ctoi) = i\n",
    "    (cfrom, cto) = (int(cfromi), int(ctoi))\n",
    "    link = (cfrom, cto)\n",
    "    a = exports.get(link,0)\n",
    "    b = imports.get((cto,cfrom),0)\n",
    "    diff = perc_diff(a,b)\n",
    "    countries_diff[link] = diff\n",
    "    if diff < 16:\n",
    "        green_countries[cfrom] = green_countries.get(cfrom, 0) + 1\n",
    "        green_countries[cto] = green_countries.get(cto, 0) + 1\n",
    "  green_countries_rank = sorted(green_countries.items(), key=itemgetter(1), reverse = True)\n",
    "  dgreen_countries_rank = {}\n",
    "  for i in range(len(green_countries_rank)):\n",
    "    dgreen_countries_rank[green_countries_rank[i][0]] = i + 1\n",
    "  df_countries_diff = pd.DataFrame(list(countries_diff.items()),columns = ['Countries Link', 'Perc Diff'])\n",
    "  df_countries_diff.sort_values(by=['Perc Diff'], inplace=True)\n",
    "  final_value_links = {}\n",
    "  for i in range(len(df_countries_diff)):\n",
    "    link = df_countries_diff['Countries Link'].iloc[i]\n",
    "    diff = df_countries_diff['Perc Diff'].iloc[i]\n",
    "    (cfrom, cto) = link\n",
    "    valueA = exports.get(link,0)\n",
    "    valueB = imports.get((cto,cfrom),0)\n",
    "    if diff < 16:\n",
    "        final_value_links[link] = (valueA + valueB) / 2\n",
    "    elif diff == 200:\n",
    "        final_value_links[link] = max(valueA, valueB)\n",
    "    else:\n",
    "        rankA = dgreen_countries_rank.get(cfrom, 0)\n",
    "        rankB = dgreen_countries_rank.get(cto, 0)\n",
    "        final_value_links[link] = get_trade_in_higher_Rank(valueA, valueB, rankA, rankB)\n",
    "  final_value_links = ISO_dict_converter(final_value_links, ISO_codes)\n",
    "  return exports,imports, df_countries_diff, green_countries, final_value_links\n",
    "\n",
    "def flatten(item):\n",
    "    (i, j) = item[0]\n",
    "    k = item[1]\n",
    "    return [i,j,k]\n",
    "\n",
    "def save_all_flow(flow, typeflow, year):\n",
    "    ### This is a function that saves as a .csv all flow for a year\n",
    "    with open('All ' + typeflow + ' Links ('+ str(year) + ').csv', 'w', newline='') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerow(['All ' + typeflow + '  Links ('+ str(year) + ')'])\n",
    "        write.writerow(['Country', 'Partner', 'Flow'])\n",
    "        write.writerows(flow)\n",
    "\n",
    "def save_all_flows(ISO_codes):\n",
    "    ### This is a function that saves all years flows in different .csv\n",
    "    TRADE_data = load_ALL_TRADE_data()\n",
    "    allyears = list(range(2001, 2020))\n",
    "    all_years_trade = []\n",
    "    for year in allyears:\n",
    "        all_years_trade.append(get_bilateral_trade(TRADE_data, year, ISO_codes))\n",
    "    for year in range(0, 19):\n",
    "        t = all_years_trade[year][4]\n",
    "        t = {k: v for k, v in t.items() if v > 0}\n",
    "        t = [flatten(k) for k in list(t.items())]\n",
    "        save_all_flow(t, 'Trade', allyears[year])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dGuXTtARsb-E",
   "metadata": {
    "id": "dGuXTtARsb-E"
   },
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ad02717-bd03-45bd-a9f3-9c6ddb455403",
   "metadata": {
    "id": "9ad02717-bd03-45bd-a9f3-9c6ddb455403"
   },
   "outputs": [],
   "source": [
    "### CAREEFUL: TAKES A LARGE AMOUNT OF TIME ≈ 10-12m\n",
    "ISO_codes = get_ISO_df()\n",
    "save_all_flows(ISO_codes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "6296b68f-0507-4e10-8ec9-ae06898582ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>All Trade  Links (2002)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <th>Partner</th>\n",
       "      <td>Flow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ECU</th>\n",
       "      <th>CRI</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ESP</th>\n",
       "      <th>LKA</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DMA</th>\n",
       "      <th>TTO</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QAT</th>\n",
       "      <th>BGD</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LTU</th>\n",
       "      <th>ECU</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWE</th>\n",
       "      <th>ARE</th>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAU</th>\n",
       "      <th>KAZ</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIH</th>\n",
       "      <th>ITA</th>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KAZ</th>\n",
       "      <th>IRQ</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11321 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                All Trade  Links (2002)\n",
       "Country Partner                    Flow\n",
       "ECU     CRI                         6.0\n",
       "ESP     LKA                        11.0\n",
       "DMA     TTO                         2.0\n",
       "QAT     BGD                         2.0\n",
       "...                                 ...\n",
       "LTU     ECU                           1\n",
       "SWE     ARE                         277\n",
       "SAU     KAZ                           1\n",
       "BIH     ITA                         277\n",
       "KAZ     IRQ                           6\n",
       "\n",
       "[11321 rows x 1 columns]"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('All Trade Links (2002).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a62f5a9c-551a-4569-a99d-43e0ddf48082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "All Trade  Links (2002)    11.0\n",
       "Name: (ESP, LKA), dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaldata = pd.read_csv('All Trade Links (2002).csv') \n",
    "finaldata.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88318409-ecd6-4941-9d87-d72dc51f8730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ESP', 'LKA')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = finaldata.iloc[2]\n",
    "row.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68ee69a9-0882-4e60-acd4-ca1b79c1c3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allyearstrade = []\n",
    "\n",
    "# this cell displays the same information than the file 'All Trade Links (year).csv' but the countries are sorted alphabetically \n",
    "\n",
    "for j in range(2001,2020): #el último número no lo incluye\n",
    "    finaldata = pd.read_csv('All Trade Links ('+ str(j) + ').csv')\n",
    "        \n",
    "    (r,c) = finaldata.shape\n",
    "    countries = np.array([])\n",
    "    partners = np.array([])\n",
    "    \n",
    "    for i in range(1,r):\n",
    "        row = finaldata.iloc[i]\n",
    "        row = row.name\n",
    "        countries = np.append(countries,row[0])\n",
    "        partners = np.append(partners,row[1])\n",
    "    \n",
    "    partnerslist = partners.tolist()\n",
    "    countrieslist = countries.tolist()\n",
    "    convertradelist = finaldata.values.tolist()\n",
    "    tradelist = convertradelist[1:]\n",
    "    tradelist = [elemento[0] for elemento in tradelist]\n",
    "    tradesarr = np.array(tradelist)\n",
    "    \n",
    "    zipped_lists = zip(countries, partners,tradesarr)\n",
    "    tradetable = sorted(zipped_lists)\n",
    "    \n",
    "    countriestable = [row[0] for row in tradetable]\n",
    "    partnerstable = [row[1] for row in tradetable]\n",
    "    flowtable = [row[2] for row in tradetable]\n",
    "    \n",
    "    \n",
    "    tradedict = {'country': countriestable, 'partner': partnerstable, 'flow': flowtable}\n",
    "    Tradedata = pd.DataFrame(data=tradedict)\n",
    "    allyearstrade.append(Tradedata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed9f1485-707d-42a8-80b9-0031d5c52a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>partner</th>\n",
       "      <th>flow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABW</td>\n",
       "      <td>JOR</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABW</td>\n",
       "      <td>NLD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABW</td>\n",
       "      <td>THA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABW</td>\n",
       "      <td>USA</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABW</td>\n",
       "      <td>VEN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13993</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>TUR</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13994</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>TWN</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13995</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>USA</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13996</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>ZAF</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>ZWE</td>\n",
       "      <td>ZMB</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13998 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country partner  flow\n",
       "0         ABW     JOR     4\n",
       "1         ABW     NLD     2\n",
       "2         ABW     THA     1\n",
       "3         ABW     USA     7\n",
       "4         ABW     VEN     3\n",
       "...       ...     ...   ...\n",
       "13993     ZWE     TUR    12\n",
       "13994     ZWE     TWN    11\n",
       "13995     ZWE     USA    47\n",
       "13996     ZWE     ZAF   135\n",
       "13997     ZWE     ZMB  55.0\n",
       "\n",
       "[13998 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tradedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "265bfbf4-06f5-40b3-a816-1f1097cfcfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it generates a different file .csv with the necessary trade data for each year.\n",
    "\n",
    "for year in range(2001,2020):\n",
    "    allyearstrade[year-2001].to_csv('allyearstrade' + str(year) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ad3a18-2a20-4081-8d4f-36a94380d0a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
